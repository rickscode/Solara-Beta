#!/usr/bin/env python3
"""
Simple Flask UI for Jupiter Limit Order Bot
Test interface for configuring and launching the working limitorder-jupitor.js bot
"""

from flask import Flask, render_template, request, jsonify, send_from_directory
import subprocess
import os
import json
import time
from pathlib import Path
import sys
import requests
from datetime import datetime
from groq import Groq
import threading
import queue
import os
from dotenv import load_dotenv
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import chromedriver_autoinstaller
from PIL import Image

# Solana imports for wallet balance
from solana.rpc.api import Client
from solders.keypair import Keypair
from solders.pubkey import Pubkey
import base58

# Add project root to Python path for imports
sys.path.insert(0, str(Path(__file__).parent))

# Load environment variables from .env file
load_dotenv()

# Import our price feed system
from simple_price_feed import get_live_price
from python_wrapper import TokenAnalysisWrapper

app = Flask(__name__)

token_analyzer = TokenAnalysisWrapper()

# Global variables to track bot process and terminal output
bot_process = None
terminal_output = []
max_terminal_lines = 1000  # Keep last 1000 lines

# JSON Config Management
def load_bot_config():
    """Load bot configuration from JSON file"""
    config_path = Path(__file__).parent / 'bot-config.json'
    try:
        with open(config_path, 'r') as f:
            return json.load(f)
    except FileNotFoundError:
        # Return empty config for production - user fills in values
        default_config = {
            "token_address": "",
            "token_symbol": "",
            "target_buy_price": "",
            "target_sell_price": "",
            "stop_loss_percentage": "",
            "amount_to_trade": "",
            "slippage_bps": 200,  # Keep a sensible default for slippage
            "dex_type": "jupiter",
            "last_updated": datetime.now().isoformat()
        }
        save_bot_config(default_config)
        return default_config
    except json.JSONDecodeError as e:
        print(f"Error parsing bot config JSON: {e}")
        # Return empty config on parse error too
        return {
            "token_address": "",
            "token_symbol": "",
            "target_buy_price": "",
            "target_sell_price": "",
            "stop_loss_percentage": "",
            "amount_to_trade": "",
            "slippage_bps": 200,
            "dex_type": "jupiter",
            "last_updated": datetime.now().isoformat()
        }

def save_bot_config(config):
    """Save bot configuration to JSON file"""
    config_path = Path(__file__).parent / 'bot-config.json'
    try:
        config['last_updated'] = datetime.now().isoformat()
        with open(config_path, 'w') as f:
            json.dump(config, f, indent=2)
        return True
    except Exception as e:
        print(f"Error saving bot config: {e}")
        return False

def send_telegram_notification(message):
    """Send notification to Telegram"""
    try:
        telegram_token = os.getenv('TELEGRAM_BOT_TOKEN')
        telegram_chat_id = os.getenv('TELEGRAM_CHAT_ID')
        
        if not telegram_token or not telegram_chat_id:
            print("Telegram credentials not configured")
            return False
            
        url = f"https://api.telegram.org/bot{telegram_token}/sendMessage"
        data = {
            'chat_id': telegram_chat_id,
            'text': message,
            'parse_mode': 'HTML'
        }
        
        response = requests.post(url, data=data, timeout=10)
        if response.status_code == 200:
            print(f"Telegram notification sent: {message}")
            return True
        else:
            print(f"Failed to send Telegram notification: {response.status_code}")
            return False
            
    except Exception as e:
        print(f"Error sending Telegram notification: {e}")
        return False

# Load bot config from JSON on startup
bot_config = load_bot_config()

def add_terminal_line(line, level='info'):
    """Add a line to the terminal output with timestamp"""
    global terminal_output
    timestamp = datetime.now().strftime("%H:%M:%S")
    terminal_output.append({
        'timestamp': timestamp,
        'line': line.strip(),
        'level': level
    })
    # Keep only the last max_terminal_lines
    if len(terminal_output) > max_terminal_lines:
        terminal_output = terminal_output[-max_terminal_lines:]

def capture_bot_output(process):
    """Capture stdout and stderr from bot process in separate thread"""
    def read_stdout():
        try:
            for line in iter(process.stdout.readline, ''):
                if not line:
                    break
                add_terminal_line(line, 'info')
        except:
            pass
    
    def read_stderr():
        try:
            for line in iter(process.stderr.readline, ''):
                if not line:
                    break
                add_terminal_line(line, 'error')
        except:
            pass
    
    # Start threads to capture both stdout and stderr
    stdout_thread = threading.Thread(target=read_stdout, daemon=True)
    stderr_thread = threading.Thread(target=read_stderr, daemon=True)
    stdout_thread.start()
    stderr_thread.start()


@app.route('/')
def index():
    """Main bot control interface"""
    return render_template('jupiter_bot_ui_enhanced.html', config=bot_config)

@app.route('/static/charts/<filename>')
def serve_chart(filename):
    """Serve chart screenshots"""
    return send_from_directory('static/charts', filename)

@app.route('/simple')
def simple_interface():
    """Simple interface (original)"""
    return render_template('jupiter_bot_ui.html', config=bot_config)


@app.route('/api/bot/start', methods=['POST'])
def start_bot():
    """Start the Jupiter limit order bot with current configuration"""
    global bot_process, bot_config
    
    try:
        # Check if bot is already running
        if bot_process and bot_process.poll() is None:
            return jsonify({
                "success": False, 
                "error": "Bot is already running"
            })
        
        # Update bot configuration with form data if provided
        if request.is_json and request.json:
            new_config = request.json
            
            # Enhanced validation to match bot file requirements
            print(f"üîç Backend validating bot configuration: {new_config}")
            
            # Validate token address - must not be empty or whitespace
            if not new_config.get('token_address') or not new_config['token_address'].strip():
                return jsonify({
                    "success": False,
                    "error": "Token address is required and cannot be empty"
                })
            
            # Validate target prices - must be greater than 0
            if not new_config.get('target_buy_price') or new_config['target_buy_price'] <= 0:
                return jsonify({
                    "success": False,
                    "error": "Buy price must be greater than 0"
                })
                
            if not new_config.get('target_sell_price') or new_config['target_sell_price'] <= 0:
                return jsonify({
                    "success": False,
                    "error": "Sell price must be greater than 0"
                })
            
            # Validate other required fields
            if not new_config.get('amount_to_trade') or new_config['amount_to_trade'] <= 0:
                return jsonify({
                    "success": False,
                    "error": "Amount to trade must be greater than 0"
                })
                
            if not new_config.get('stop_loss_percentage') or new_config['stop_loss_percentage'] <= 0:
                return jsonify({
                    "success": False,
                    "error": "Stop loss percentage must be greater than 0"
                })
            
            # Validate slippage
            slippage = new_config.get('slippage_bps', 200)  # Default to 200 if not provided
            if slippage < 50 or slippage > 1000:
                return jsonify({
                    "success": False,
                    "error": "Slippage must be between 50-1000 BPS (0.5%-10%)"
                })
            
            print("‚úÖ Backend validation passed")
            
            # Validate configuration values
            required_fields = ['token_address', 'target_buy_price', 'target_sell_price', 'amount_to_trade', 'stop_loss_percentage']
            for field in required_fields:
                if field not in new_config:
                    return jsonify({
                        "success": False,
                        "error": f"Missing required field: {field}"
                    })
            
            # Validate numeric values
            try:
                if new_config['target_buy_price'] <= 0:
                    raise ValueError("Buy price must be positive")
                if new_config['target_sell_price'] <= 0:
                    raise ValueError("Sell price must be positive")
                if new_config['target_buy_price'] > new_config['target_sell_price']:
                    raise ValueError("Sell price must be higher than or equal to buy price")
                if new_config['amount_to_trade'] <= 0:
                    raise ValueError("Amount to trade must be positive")
                if new_config['stop_loss_percentage'] <= 0 or new_config['stop_loss_percentage'] >= 100:
                    raise ValueError("Stop loss percentage must be between 0 and 100")
            except ValueError as e:
                return jsonify({
                    "success": False,
                    "error": str(e)
                })
            
            # Update global bot config
            bot_config.update({
                'token_address': new_config['token_address'],
                'target_buy_price': float(new_config['target_buy_price']),
                'target_sell_price': float(new_config['target_sell_price']),
                'amount_to_trade': float(new_config['amount_to_trade']),
                'stop_loss_percentage': float(new_config['stop_loss_percentage'])
            })
            
            # Update token symbol dynamically - try to get from token stats
            try:
                # Try to get token data to extract symbol
                token_stats = get_comprehensive_token_data(new_config['token_address'])
                token_name = token_stats.get('rugcheck', {}).get('token_name', '')
                token_symbol = token_stats.get('rugcheck', {}).get('token_symbol', '')
                
                if token_symbol:
                    bot_config['token_symbol'] = token_symbol
                elif token_name:
                    bot_config['token_symbol'] = token_name[:10]  # Truncate if too long
                else:
                    bot_config['token_symbol'] = 'TOKEN'  # Generic fallback
            except:
                bot_config['token_symbol'] = 'TOKEN'  # Generic fallback on error
            
            print(f"Updated bot config: {bot_config}")
        
        # Detect primary DEX for the token
        primary_dex = get_primary_dex(bot_config['token_address'])
        add_terminal_line(f"Detected primary DEX: {primary_dex.upper()}", 'info')
        
        # Select the appropriate bot script (no more modification needed)
        if primary_dex == 'raydium':
            bot_script = 'limitorder-raydium.js'
            add_terminal_line("Starting Raydium SDK trading bot with nodemon...", 'info')
        else:
            bot_script = 'limitorder-jupitor.js'
            add_terminal_line("Starting Jupiter aggregator trading bot with nodemon...", 'info')
        
        # Clear previous terminal output
        global terminal_output
        terminal_output = []
        
        add_terminal_line("Bot will auto-restart when configuration changes", 'info')
        
        # Launch the bot with nodemon watching the JSON config file
        bot_process = subprocess.Popen(
            ['nodemon', '--watch', 'bot-config.json', '--exec', 'node', bot_script],
            cwd=Path(__file__).parent,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            bufsize=1,
            universal_newlines=True
        )
        
        # Start capturing output in separate thread
        capture_bot_output(bot_process)
        
        return jsonify({
            "success": True,
            "message": f"Jupiter bot started with PID {bot_process.pid}",
            "config": bot_config
        })
        
    except Exception as e:
        return jsonify({
            "success": False,
            "error": f"Failed to start bot: {str(e)}"
        })

@app.route('/api/bot/stop', methods=['POST'])
def stop_bot():
    """Stop the running bot"""
    global bot_process
    
    try:
        if bot_process and bot_process.poll() is None:
            bot_process.terminate()
            time.sleep(2)
            
            # Force kill if still running
            if bot_process.poll() is None:
                bot_process.kill()
            
            bot_process = None
            add_terminal_line("Bot stopped by user", 'warn')
            
            # Send Telegram notification
            config = load_bot_config()
            token_symbol = config.get('token_symbol', 'TOKEN')
            stop_message = f"üõë <b>Bot Stopped</b>\n\nüìä Token: {token_symbol}\n‚è∞ Time: {datetime.now().strftime('%H:%M:%S')}\n\n‚úã Bot stopped by user command"
            send_telegram_notification(stop_message)
            
            return jsonify({
                "success": True,
                "message": "Bot stopped successfully"
            })
        else:
            return jsonify({
                "success": False,
                "error": "No bot is currently running"
            })
            
    except Exception as e:
        return jsonify({
            "success": False,
            "error": f"Failed to stop bot: {str(e)}"
        })

@app.route('/api/bot/status')
def bot_status():
    """Get current bot status"""
    global bot_process, bot_config
    
    if bot_process and bot_process.poll() is None:
        return jsonify({
            "running": True,
            "pid": bot_process.pid,
            "config": bot_config
        })
    else:
        return jsonify({
            "running": False,
            "pid": None,
            "config": bot_config
        })

@app.route('/api/bot/config', methods=['GET'])
def get_config():
    """Get current bot configuration"""
    try:
        config = load_bot_config()
        return jsonify({
            "success": True,
            "config": config
        })
    except Exception as e:
        print(f"Error loading config: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        })

@app.route('/api/bot/save-config', methods=['POST'])
def save_config():
    """Save bot configuration and optionally restart bot"""
    global bot_config, bot_process
    
    try:
        # Get new configuration from request
        new_config = request.get_json()
        
        if not new_config:
            return jsonify({
                "success": False,
                "error": "No configuration data provided"
            })
        
        # Validate required fields
        required_fields = ['token_address', 'target_buy_price', 'target_sell_price', 
                          'amount_to_trade', 'stop_loss_percentage']
        for field in required_fields:
            if field not in new_config:
                return jsonify({
                    "success": False,
                    "error": f"Missing required field: {field}"
                })
        
        # Check if bot is currently running
        bot_was_running = bot_process and bot_process.poll() is None
        
        # Update bot_config with new values
        bot_config.update({
            'token_address': new_config['token_address'],
            'target_buy_price': float(new_config['target_buy_price']),
            'target_sell_price': float(new_config['target_sell_price']),
            'amount_to_trade': float(new_config['amount_to_trade']),
            'stop_loss_percentage': float(new_config['stop_loss_percentage']),
            'slippage_bps': int(new_config.get('slippage_bps', 200))
        })
        
        # Update token symbol if provided
        if 'token_symbol' in new_config:
            bot_config['token_symbol'] = new_config['token_symbol']
        
        # Save to JSON file
        if not save_bot_config(bot_config):
            return jsonify({
                "success": False,
                "error": "Failed to save configuration to file"
            })
        
        add_terminal_line("Configuration updated successfully", 'info')
        
        # If bot was running, restart it with new config
        if bot_was_running:
            add_terminal_line("Restarting bot with new configuration...", 'info')
            
            # Stop current bot
            if bot_process:
                bot_process.terminate()
                time.sleep(2)
                if bot_process.poll() is None:
                    bot_process.kill()
                bot_process = None
            
            # Start bot with new config (will use updated JSON file)
            primary_dex = get_primary_dex(bot_config['token_address'])
            
            # Select the appropriate bot script
            if primary_dex == 'raydium':
                bot_script = 'limitorder-raydium.js'
            else:
                bot_script = 'limitorder-jupitor.js'
            
            bot_process = subprocess.Popen(
                ['nodemon', '--watch', 'bot-config.json', '--exec', 'node', bot_script],
                cwd=Path(__file__).parent,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                bufsize=1,
                universal_newlines=True
            )
            
            # Start capturing output in separate thread
            capture_bot_output(bot_process)
            
            return jsonify({
                "success": True,
                "message": "Configuration saved and bot restarted",
                "config": bot_config,
                "restarted": True
            })
        else:
            return jsonify({
                "success": True,
                "message": "Configuration saved successfully",
                "config": bot_config,
                "restarted": False
            })
            
    except ValueError as e:
        return jsonify({
            "success": False,
            "error": f"Invalid numeric value in configuration: {str(e)}"
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": f"Failed to save configuration: {str(e)}"
        })

@app.route('/api/terminal/output')
def get_terminal_output():
    """Get current terminal output"""
    global terminal_output
    return jsonify({
        "success": True,
        "output": terminal_output
    })

@app.route('/api/terminal/clear', methods=['POST'])
def clear_terminal():
    """Clear terminal output"""
    global terminal_output
    terminal_output = []
    return jsonify({
        "success": True,
        "message": "Terminal cleared"
    })

@app.route('/api/wallet/balance')
def get_wallet_balance():
    """Get current wallet SOL balance"""
    try:
        # Get wallet private key from environment
        private_key = os.getenv('WALLET_PRIVATE_KEY')
        rpc_url = os.getenv('RPC_URL', 'https://api.mainnet-beta.solana.com')
        
        if not private_key:
            return jsonify({
                "success": False,
                "balance": 0.0,
                "error": "Wallet not configured. Please complete setup first."
            })
        
        # Create Solana client
        client = Client(rpc_url)
        
        # Create keypair from private key
        try:
            # Decode base58 private key
            private_key_bytes = base58.b58decode(private_key)
            keypair = Keypair.from_bytes(private_key_bytes)
            
            # Get balance in lamports
            response = client.get_balance(keypair.pubkey())
            
            # Handle Solana RPC response format
            if isinstance(response, dict):
                # Standard RPC response: {'jsonrpc': '2.0', 'result': {'context': {...}, 'value': 14556317}, 'id': 1}
                if 'result' in response and 'value' in response['result']:
                    balance_lamports = response['result']['value']
                else:
                    balance_lamports = response.get('value', 0)
            elif hasattr(response, 'value'):
                balance_lamports = response.value
            else:
                balance_lamports = response
            
            # Convert lamports to SOL (1 SOL = 1,000,000,000 lamports)
            balance_sol = balance_lamports / 1_000_000_000
            
            return jsonify({
                "success": True,
                "balance": round(balance_sol, 6),
                "balance_lamports": balance_lamports,
                "wallet_address": str(keypair.pubkey()),
                "message": f"Wallet balance: {balance_sol:.6f} SOL"
            })
            
        except Exception as key_error:
            return jsonify({
                "success": False,
                "balance": 0.0,
                "error": f"Invalid wallet private key: {str(key_error)}"
            })
            
    except Exception as e:
        return jsonify({
            "success": False,
            "balance": 0.0,
            "error": f"Connection error: {str(e)}"
        })

@app.route('/api/reload-config', methods=['POST'])
def reload_configuration():
    """Reload environment configuration without restarting server"""
    try:
        # Reload .env file
        load_dotenv(override=True)
        
        # Test if configuration is valid
        private_key = os.getenv('WALLET_PRIVATE_KEY')
        groq_key = os.getenv('GROQ_API_KEY')
        
        return jsonify({
            "success": True,
            "message": "Configuration reloaded successfully",
            "wallet_configured": bool(private_key),
            "groq_configured": bool(groq_key)
        })
        
    except Exception as e:
        return jsonify({
            "success": False,
            "error": f"Failed to reload configuration: {str(e)}"
        })

@app.route('/api/bot/close-position', methods=['POST'])
def close_position():
    """Close current position by selling all tokens immediately"""
    try:
        # Load current configuration
        config = load_bot_config()
        token_address = config.get('token_address')
        
        if not token_address or token_address.strip() == '':
            return jsonify({
                "success": False,
                "error": "No token address configured"
            })
        
        # Detect primary DEX for the token
        primary_dex = get_primary_dex(token_address)
        add_terminal_line(f"üîª Closing position for {token_address[:8]}... via {primary_dex.upper()}", 'warning')
        
        # Create a temporary liquidation script based on DEX type
        script_path = create_liquidation_script(primary_dex, token_address)
        
        if not script_path:
            return jsonify({
                "success": False,
                "error": "Failed to create liquidation script"
            })
        
        # Execute liquidation
        add_terminal_line("üèÉ‚Äç‚ôÇÔ∏è Executing immediate liquidation...", 'info')
        
        try:
            # Run the liquidation script
            result = subprocess.run(
                ['node', str(script_path)],
                cwd=str(Path(__file__).parent),
                capture_output=True,
                text=True,
                timeout=60  # 60 second timeout for liquidation
            )
            
            if result.returncode == 0:
                add_terminal_line("‚úÖ Position closed successfully", 'success')
                return jsonify({
                    "success": True,
                    "message": "Position closed successfully",
                    "dex_used": primary_dex,
                    "output": result.stdout
                })
            else:
                add_terminal_line(f"‚ùå Liquidation failed: {result.stderr}", 'error')
                return jsonify({
                    "success": False,
                    "error": f"Liquidation script failed: {result.stderr}"
                })
                
        except subprocess.TimeoutExpired:
            add_terminal_line("‚è∞ Liquidation timed out", 'error')
            return jsonify({
                "success": False,
                "error": "Liquidation timed out after 60 seconds"
            })
        finally:
            # Clean up temporary script
            if script_path.exists():
                script_path.unlink()
        
    except Exception as e:
        add_terminal_line(f"‚ùå Error closing position: {str(e)}", 'error')
        return jsonify({
            "success": False,
            "error": str(e)
        })

@app.route('/api/setup/save-env', methods=['POST'])
def save_environment_config():
    """Save environment configuration to .env file"""
    try:
        data = request.get_json()
        
        # Validate required fields
        if not data.get('wallet_private_key'):
            return jsonify({
                'success': False, 
                'message': 'Wallet private key is required'
            })
        
        if not data.get('rpc_url'):
            return jsonify({
                'success': False, 
                'message': 'RPC URL is required'
            })
            
        if not data.get('groq_api_key'):
            return jsonify({
                'success': False, 
                'message': 'Groq API key is required for AI analysis features'
            })
        
        # Validate wallet private key format (basic Base58 check)
        wallet_key = data['wallet_private_key'].strip()
        if len(wallet_key) < 64 or len(wallet_key) > 88:
            return jsonify({
                'success': False, 
                'message': 'Invalid wallet private key length'
            })
        
        # Basic Base58 character validation
        import re
        if not re.match(r'^[1-9A-HJ-NP-Za-km-z]+$', wallet_key):
            return jsonify({
                'success': False, 
                'message': 'Invalid wallet private key format (must be Base58)'
            })
        
        # Create .env content
        env_content = create_env_file_content(data)
        
        # Write to .env file (direct overwrite for clean UX)
        env_path = Path(__file__).parent / '.env'
        
        # Write new .env file directly
        with open(env_path, 'w') as f:
            f.write(env_content)
        
        # Set secure file permissions (owner read/write only)
        os.chmod(env_path, 0o600)
        
        # Automatically reload configuration without server restart
        try:
            load_dotenv(override=True)
            add_terminal_line("‚úÖ Configuration saved and reloaded successfully! No server restart needed.", 'success')
            
            return jsonify({
                'success': True, 
                'message': 'Configuration saved and reloaded successfully! No server restart needed.',
                'auto_reloaded': True
            })
        except Exception as reload_error:
            add_terminal_line(f"‚ö†Ô∏è Configuration saved but reload failed: {str(reload_error)}. Please restart server.", 'warning')
            
            return jsonify({
                'success': True, 
                'message': 'Configuration saved successfully! Please restart the server to apply changes.',
                'auto_reloaded': False,
                'reload_error': str(reload_error)
            })
        
    except Exception as e:
        add_terminal_line(f"‚ùå Error saving configuration: {str(e)}", 'error')
        return jsonify({
            'success': False, 
            'message': f'Error saving configuration: {str(e)}'
        })

def create_env_file_content(data):
    """Create .env file content from configuration data"""
    content = """# ===== WALLET CONFIGURATION =====
WALLET_PRIVATE_KEY={wallet_private_key}
RPC_URL={rpc_url}

# ===== AI CONFIGURATION =====
GROQ_API_KEY={groq_api_key}
""".format(
        wallet_private_key=data['wallet_private_key'],
        rpc_url=data['rpc_url'],
        groq_api_key=data['groq_api_key']
    )
    
    # Add optional Telegram configuration
    if data.get('telegram_bot_token') and data.get('telegram_chat_id'):
        content += """
# ===== TELEGRAM CONFIGURATION =====
TELEGRAM_BOT_TOKEN={telegram_bot_token}
TELEGRAM_CHAT_ID={telegram_chat_id}
""".format(
            telegram_bot_token=data['telegram_bot_token'],
            telegram_chat_id=data['telegram_chat_id']
        )
    
    # Add optional Cloudflare configuration
    if data.get('cloudflare_account_id') and data.get('cloudflare_api_token'):
        content += """
# ===== CLOUDFLARE AI CONFIGURATION =====
CLOUDFLARE_ACCOUNT_ID={cloudflare_account_id}
CLOUDFLARE_API_TOKEN={cloudflare_api_token}
""".format(
            cloudflare_account_id=data['cloudflare_account_id'],
            cloudflare_api_token=data['cloudflare_api_token']
        )
    
    # Add trading configuration defaults
    content += """
# ===== TRADING CONFIGURATION =====
MIN_PROFIT_PROBABILITY=0.1
STOP_LOSS_PERCENTAGE=0.15

# ===== FLASK DEVELOPMENT CONFIGURATION =====
FLASK_ENV=development
FLASK_DEBUG=1
FLASK_APP=jupiter_bot_ui.py
HOST=127.0.0.1
PORT=8080
TEMPLATES_AUTO_RELOAD=True
"""
    
    return content

@app.route('/api/price/<token_address>')
def get_token_price(token_address):
    """Get current token price"""
    try:
        price_data = get_live_price(token_address)
        if price_data:
            return jsonify({
                "success": True,
                "price_usd": price_data['priceUsd'],
                "price_sol": price_data['priceSol'],
                "source": price_data['source'],
                "change_24h": price_data['change24h'],
                "timestamp": time.time()
            })
        else:
            return jsonify({
                "success": False, 
                "error": "No price data available"
            })
    except Exception as e:
        return jsonify({
            "success": False, 
            "error": str(e)
        })

@app.route('/api/token-stats/<token_address>')
def get_token_stats(token_address):
    """Get comprehensive token statistics"""
    try:
        # Validate token address format
        if not token_address or len(token_address) < 32 or len(token_address) > 44:
            return jsonify({
                "success": False,
                "error": "Invalid token address format - must be 32-44 characters",
                "error_code": "INVALID_ADDRESS"
            })
        
        # Get comprehensive token data from DexScreener
        stats_data = get_comprehensive_token_data(token_address)
        
        # Check if we got error data back
        if isinstance(stats_data, dict) and stats_data.get('error'):
            return jsonify({
                "success": False,
                "error": stats_data['error'],
                "error_code": "TOKEN_DATA_ERROR"
            })
        
        return jsonify({
            "success": True,
            "data": stats_data,
            "timestamp": time.time()
        })
    except Exception as e:
        error_message = str(e)
        error_code = "UNKNOWN_ERROR"
        
        # Categorize common errors
        if "no pairs found" in error_message.lower():
            error_code = "TOKEN_NOT_FOUND"
        elif "timeout" in error_message.lower():
            error_code = "API_TIMEOUT" 
        elif "connection" in error_message.lower():
            error_code = "CONNECTION_ERROR"
        elif "rugcheck" in error_message.lower():
            error_code = "RUGCHECK_ERROR"
            
        return jsonify({
            "success": False,
            "error": error_message,
            "error_code": error_code
        })

@app.route('/api/trades/<token_address>')
def get_recent_trades(token_address):
    """Get recent trades for the token"""
    try:
        trades_data = fetch_recent_trades(token_address)
        return jsonify({
            "success": True,
            "trades": trades_data,
            "timestamp": time.time()
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        })


@app.route('/api/llm-analysis/<token_address>', methods=['GET', 'POST'])
def get_llm_analysis(token_address):
    """Get comprehensive LLM analysis for the token using 5-model AI analysis"""
    try:
        uploaded_chart = None
        
        # Handle POST request with uploaded chart data
        if request.method == 'POST':
            data = request.get_json()
            if data and 'uploaded_chart' in data:
                uploaded_chart = data['uploaded_chart']
                print(f"Received uploaded chart: {uploaded_chart['filename']}")
        
        # Run comprehensive AI analysis with 5 models (including uploaded chart if provided)
        analysis_result = run_comprehensive_ai_analysis(token_address, uploaded_chart)
        
        if not analysis_result:
            return jsonify({
                "success": False,
                "error": "Failed to generate AI analysis"
            })
        
        return jsonify({
            "success": True,
            "analysis": analysis_result,
            "timestamp": datetime.now().isoformat()
        })
        
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        })


@app.route('/api/rugcheck-data/<token_address>')
def get_rugcheck_security_data(token_address):
    """Get comprehensive rugcheck security data for display"""
    try:
        rugcheck_data = get_rugcheck_data(token_address)
        return jsonify({
            "success": True,
            "data": rugcheck_data,
            "timestamp": time.time()
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        })

@app.route('/api/chart-screenshot/<token_address>')
def get_chart_screenshot(token_address):
    """Capture and return DEXTools chart screenshot"""
    try:
        result = capture_dextools_chart(token_address)
        return jsonify(result)
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e),
            "message": "Failed to capture chart screenshot"
        })


def calculate_lp_locked_percentage(markets):
    """Calculate LP locked percentage - try weighted average first, fallback to max"""
    if not markets or not isinstance(markets, list):
        return 0
    
    try:
        # Try weighted calculation based on USD liquidity (to match rugcheck.xyz)
        total_liquidity_usd = 0
        total_locked_liquidity_usd = 0
        max_lp_locked = 0
        
        for market in markets:
            if not isinstance(market, dict):
                continue
                
            lp_data = market.get('lp', {})
            if not isinstance(lp_data, dict):
                continue
                
            lp_locked_pct = lp_data.get('lpLockedPct', 0)
            lp_locked_usd = lp_data.get('lpLockedUSD', 0)
            base_usd = lp_data.get('baseUSD', 0)
            quote_usd = lp_data.get('quoteUSD', 0)
            total_market_usd = base_usd + quote_usd
            
            # Track max for fallback
            if isinstance(lp_locked_pct, (int, float)) and lp_locked_pct > max_lp_locked:
                max_lp_locked = lp_locked_pct
            
            # Accumulate for weighted calculation
            if isinstance(lp_locked_usd, (int, float)) and isinstance(total_market_usd, (int, float)):
                total_liquidity_usd += total_market_usd
                total_locked_liquidity_usd += lp_locked_usd
        
        # Use weighted average if we have liquidity data
        if total_liquidity_usd > 0:
            weighted_percentage = (total_locked_liquidity_usd / total_liquidity_usd) * 100
            return round(weighted_percentage, 2)
        else:
            # Fallback to max percentage
            return round(max_lp_locked, 2)
            
    except Exception as e:
        print(f"Error in calculate_lp_locked_percentage: {e}")
        return 0

def get_market_lp_breakdown(markets):
    """Get LP breakdown by market type (first occurrence only)"""
    if not markets or not isinstance(markets, list):
        return {}
    
    market_breakdown = {}
    seen_market_types = set()
    
    # Convert market type to readable name
    readable_names = {
        'pump_fun_amm': 'Pump Fun AMM',
        'meteora': 'Meteora',
        'meteoraDlmm': 'Meteora DLMM',
        'meteoraDamm': 'Meteora DAMM',
        'raydium_clmm': 'Raydium CLMM', 
        'raydium_cpmm': 'Raydium CPMM',
        'raydium_amm': 'Raydium AMM',
        'orca_whirlpool': 'Orca Whirlpool'
    }
    
    try:
        for market in markets:
            if not isinstance(market, dict):
                continue
                
            market_type = market.get('marketType', 'unknown')
            
            # Only show first occurrence of each market type
            if market_type not in seen_market_types:
                seen_market_types.add(market_type)
                
                # Get LP locked percentage
                lp_locked_pct = 0
                if 'lp' in market and isinstance(market.get('lp'), dict):
                    lp_locked_pct = market['lp'].get('lpLockedPct', 0)
                elif 'lpLockedPct' in market:
                    lp_locked_pct = market.get('lpLockedPct', 0)
                
                readable_name = readable_names.get(market_type, market_type)
                market_breakdown[market_type] = {
                    'name': readable_name,
                    'percentage': round(float(lp_locked_pct or 0), 2)
                }
    except Exception as e:
        print(f"Error in get_market_lp_breakdown: {e}")
        return {}
    
    return market_breakdown

def get_rugcheck_data(token_address):
    """Get comprehensive rugcheck security data"""
    try:
        # Get full rugcheck report (not just summary)
        url = f"https://api.rugcheck.xyz/v1/tokens/{token_address}/report"
        response = requests.get(url, headers={'Accept': 'application/json'}, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            
            # Extract key metrics for display and analysis with error handling
            try:
                # Calculate LP locked percentage from markets data
                markets_data = data.get('markets', []) or []
                lp_locked_pct = calculate_lp_locked_percentage(markets_data)
                market_lp_breakdown = get_market_lp_breakdown(markets_data)
                
                # Use normalized score if available, otherwise raw score (FIX FOR SCORE ISSUE)
                normalized_score = data.get('score_normalised')
                raw_score = data.get('score')
                final_score = normalized_score if normalized_score is not None else (raw_score if raw_score is not None else 999)
                
                result = {
                    "score": final_score,  # Use normalized score for consistency with rugcheck.xyz
                    "score_normalised": data.get('score_normalised', 1),
                    "rugged": data.get('rugged', False),
                    "risks": data.get('risks') or [],
                    "lp_locked_pct": lp_locked_pct,
                    "market_lp_breakdown": market_lp_breakdown,  # New: breakdown by market type
                    "total_holders": data.get('totalHolders', 0),
                    "total_markets": len(data.get('markets') or []),
                    "total_market_liquidity": data.get('totalMarketLiquidity', 0),
                    "total_stable_liquidity": data.get('totalStableLiquidity', 0),
                    "insiders_detected": data.get('graphInsidersDetected', 0),
                    "insider_networks": len(data.get('insiderNetworks') or []),
                    "mint_authority": data.get('token', {}).get('mintAuthority'),
                    "freeze_authority": data.get('token', {}).get('freezeAuthority'),
                    "token_name": data.get('fileMeta', {}).get('name', ''),
                    "token_symbol": data.get('fileMeta', {}).get('symbol', ''),
                    "creator_balance": data.get('creatorBalance', 0),
                    "verification": data.get('verification') or {},
                    "top_holders": (data.get('topHolders') or [])[:10],  # Top 10 holders
                    "full_data": data  # Store full data for AI analysis
                }
                print(f"Successfully processed rugcheck data, score: {result['score']}")
                return result
            except Exception as e:
                print(f"Error processing rugcheck data: {e}")
                return {"error": str(e), "score": 999}
        
        # Fallback to summary endpoint if full report fails
        print(f"Full rugcheck report failed, trying summary for {token_address}")
        summary_url = f"https://api.rugcheck.xyz/v1/tokens/{token_address}/report/summary"
        summary_response = requests.get(summary_url, headers={'Accept': 'application/json'}, timeout=5)
        
        if summary_response.status_code == 200:
            summary_data = summary_response.json()
            return {
                "score": summary_data.get('score', 999),
                "score_normalised": summary_data.get('score_normalised', 1),
                "rugged": False,
                "risks": summary_data.get('risks', []),
                "lp_locked_pct": summary_data.get('lpLockedPct', 0),
                "total_holders": 0,
                "total_markets": 0,
                "total_market_liquidity": 0,
                "total_stable_liquidity": 0,
                "insiders_detected": 0,
                "insider_networks": 0,
                "mint_authority": None,
                "freeze_authority": None,
                "token_name": '',
                "token_symbol": '',
                "creator_balance": 0,
                "verification": {},
                "top_holders": [],
                "full_data": summary_data,
                "summary_only": True
            }
        
        return {"error": f"Rugcheck API failed with status {response.status_code}", "score": 999}
        
    except Exception as e:
        print(f"Error fetching rugcheck data for {token_address}: {e}")
        return {"error": str(e), "score": 999}

def get_comprehensive_token_data(token_address):
    """Get comprehensive token data from DexScreener and Rugcheck"""
    try:
        # Get token data from DexScreener API
        url = f"https://api.dexscreener.com/latest/dex/tokens/{token_address}"
        response = requests.get(url, timeout=10)
        
        token_data = {
            "price_usd": 0,
            "price_change_5m": 0,
            "price_change_1h": 0,
            "price_change_6h": 0,
            "price_change_24h": 0,
            "volume_24h": 0,
            "liquidity": 0,
            "market_cap": 0,
            "fdv": 0,
            "transactions_24h": {"buys": 0, "sells": 0},
            "pair_address": "",
            "dex": "",
            "pool_created_at": 0,
            "token_symbol": "TOKEN",
            "token_name": ""
        }
        
        if response.status_code == 200:
            data = response.json()
            
            if data.get('pairs') and len(data['pairs']) > 0:
                # Get the primary SOL pair
                sol_pair = None
                for pair in data['pairs']:
                    if 'SOL' in pair.get('baseToken', {}).get('symbol', '') or 'SOL' in pair.get('quoteToken', {}).get('symbol', ''):
                        sol_pair = pair
                        break
                
                if not sol_pair:
                    sol_pair = data['pairs'][0]  # Fallback to first pair
                
                price_changes = sol_pair.get('priceChange', {})
                token_data.update({
                    "price_usd": float(sol_pair.get('priceUsd', 0)),
                    "price_change_5m": float(price_changes.get('m5', 0)),
                    "price_change_1h": float(price_changes.get('h1', 0)),
                    "price_change_6h": float(price_changes.get('h6', 0)),
                    "price_change_24h": float(price_changes.get('h24', 0)),
                    "volume_24h": float(sol_pair.get('volume', {}).get('h24', 0)),
                    "liquidity": float(sol_pair.get('liquidity', {}).get('usd', 0)),
                    "market_cap": float(sol_pair.get('marketCap', 0)),
                    "fdv": float(sol_pair.get('fdv', 0)),
                    "transactions_24h": {
                        "buys": sol_pair.get('txns', {}).get('h24', {}).get('buys', 0),
                        "sells": sol_pair.get('txns', {}).get('h24', {}).get('sells', 0)
                    },
                    "pair_address": sol_pair.get('pairAddress', ''),
                    "dex": sol_pair.get('dexId', ''),
                    "pool_created_at": sol_pair.get('pairCreatedAt', 0)
                })
                
                # Extract token symbol from baseToken or quoteToken (whichever is not SOL)
                base_token = sol_pair.get('baseToken', {})
                quote_token = sol_pair.get('quoteToken', {})
                
                if base_token.get('symbol', '') != 'SOL':
                    token_data['token_symbol'] = base_token.get('symbol', 'TOKEN')
                    token_data['token_name'] = base_token.get('name', '')
                elif quote_token.get('symbol', '') != 'SOL':
                    token_data['token_symbol'] = quote_token.get('symbol', 'TOKEN')
                    token_data['token_name'] = quote_token.get('name', '')
                else:
                    token_data['token_symbol'] = 'TOKEN'
                    token_data['token_name'] = ''
        
        # Get rugcheck security data
        rugcheck_data = get_rugcheck_data(token_address)
        
        # Merge rugcheck data into token data
        lp_locked_pct = rugcheck_data.get('lp_locked_pct', 0)
        
        # Determine locked status based on rugcheck API data
        # Check if there are active lockers (indicates professional LP locking)
        lockers = rugcheck_data.get('full_data', {}).get('lockers', {})
        has_active_lockers = len(lockers) > 0
        
        # Consider "locked" if LP% > 50% OR there are active lockers (matches rugcheck.xyz logic)
        liquidity_locked = lp_locked_pct >= 50 or has_active_lockers
        
        token_data.update({
            "rugcheck": rugcheck_data,
            "rugcheck_score": rugcheck_data.get('score', 999),
            "rugcheck_risk_level": calculate_rugcheck_risk_level(rugcheck_data.get('score', 999)),
            "lp_locked_pct": lp_locked_pct,
            "liquidity_locked": liquidity_locked,
            "total_holders": rugcheck_data.get('total_holders', 0),
            "total_markets": rugcheck_data.get('total_markets', 0)
        })
        
        return token_data
        
    except Exception as e:
        print(f"Error fetching comprehensive token data: {e}")
        return {"error": str(e), "rugcheck_score": 999}

def calculate_rugcheck_risk_level(score):
    """Calculate risk level based on rugcheck score (lower score = lower risk)"""
    if score <= 1:
        return "EXCELLENT"
    elif score <= 5:
        return "GOOD"
    elif score <= 10:
        return "MODERATE"
    elif score <= 25:
        return "HIGH"
    else:
        return "VERY_HIGH"

def get_primary_dex(token_address):
    """Determine primary DEX for token based on highest liquidity"""
    try:
        print(f"Detecting primary DEX for token: {token_address}")
        stats_data = get_comprehensive_token_data(token_address)
        primary_dex = stats_data.get('dex', '').lower()
        
        print(f"Primary DEX detected: {primary_dex}")
        
        # Return 'raydium' if primary DEX is Raydium, otherwise 'jupiter'
        if primary_dex == 'raydium':
            return 'raydium'
        else:
            return 'jupiter'  # Default to Jupiter for all other DEXs
            
    except Exception as e:
        print(f"Error detecting primary DEX: {e}")
        return 'jupiter'  # Safe fallback to Jupiter

def fetch_recent_trades(token_address, limit=50):
    """Fetch recent trades from multiple sources"""
    try:
        # For now, we'll simulate trade data since getting real-time trades requires more complex APIs
        # In production, you'd integrate with Solscan, Birdeye, or DEX-specific APIs
        
        # Get basic price data first
        price_data = get_live_price(token_address)
        if not price_data:
            return []
        
        current_price = price_data['priceUsd']
        
        # Generate simulated recent trades based on volume and activity
        import random
        trades = []
        
        for i in range(min(limit, 20)):  # Limit to 20 simulated trades
            trade_type = random.choice(['buy', 'sell'])
            price_variation = random.uniform(0.98, 1.02)  # ¬±2% price variation
            trade_price = current_price * price_variation
            
            amount_usd = random.uniform(10, 1000)  # $10 to $1000 trade sizes
            amount_tokens = amount_usd / trade_price
            
            # Timestamp within last hour
            timestamp = int(time.time()) - random.randint(60, 3600)
            
            trades.append({
                "type": trade_type,
                "price": round(trade_price, 8),
                "amount_usd": round(amount_usd, 2),
                "amount_tokens": round(amount_tokens, 2),
                "timestamp": timestamp,
                "tx_hash": f"simulated_{i}_{int(time.time())}"
            })
        
        # Sort by timestamp (newest first)
        trades.sort(key=lambda x: x['timestamp'], reverse=True)
        return trades
        
    except Exception as e:
        print(f"Error fetching trades: {e}")
        return []

def process_uploaded_chart(uploaded_chart):
    """Process uploaded chart data and save it for analysis"""
    try:
        import base64
        import time
        
        # Decode base64 image data
        image_data = base64.b64decode(uploaded_chart['data'])
        
        # Create filename with timestamp
        timestamp = int(time.time())
        filename = f"uploaded_chart_{timestamp}.{uploaded_chart['mimeType'].split('/')[-1]}"
        filepath = f"static/charts/{filename}"
        
        # Ensure static/charts directory exists
        os.makedirs("static/charts", exist_ok=True)
        
        # Save uploaded chart
        with open(filepath, 'wb') as f:
            f.write(image_data)
        
        return {
            "success": True,
            "url": f"/static/charts/{filename}",
            "filename": uploaded_chart['filename'],
            "original_filename": uploaded_chart['filename'],
            "local_path": filepath
        }
    except Exception as e:
        print(f"Error processing uploaded chart: {e}")
        return {
            "success": False,
            "error": str(e)
        }

def run_comprehensive_ai_analysis(token_address, uploaded_chart=None):
    """Run comprehensive AI analysis using real Groq models"""
    try:
        # Initialize Groq client
        groq_api_key = os.getenv('GROQ_API_KEY')
        if not groq_api_key:
            print("Warning: GROQ_API_KEY not found, using simulated analysis")
            return run_simulated_ai_analysis(token_address, uploaded_chart)
        
        client = Groq(api_key=groq_api_key)
        
        # Get current market data
        token_stats = get_comprehensive_token_data(token_address)
        price_data = get_live_price(token_address)
        
        if not price_data:
            raise Exception("Could not fetch price data for analysis")
        
        current_price = price_data['priceUsd']
        
        # Prepare market data for AI analysis including rugcheck security data
        rugcheck_data = token_stats.get('rugcheck', {})
        market_data = {
            "current_price": current_price,
            "price_change_24h": token_stats.get('price_change_24h', 0),
            "volume_24h": token_stats.get('volume_24h', 0),
            "liquidity": token_stats.get('liquidity', 0),
            "market_cap": token_stats.get('market_cap', 0),
            "transactions_24h": token_stats.get('transactions_24h', {}),
            "token_address": token_address,
            "rugcheck_score": rugcheck_data.get('score', 999),
            "rugcheck_risk_level": token_stats.get('rugcheck_risk_level', 'UNKNOWN'),
            "lp_locked_pct": rugcheck_data.get('lp_locked_pct', 0),
            "market_lp_breakdown": rugcheck_data.get('market_lp_breakdown', {}),  # New: LP breakdown by market type
            "total_holders": rugcheck_data.get('total_holders', 0),
            "total_markets": rugcheck_data.get('total_markets', 0),
            "rugged": rugcheck_data.get('rugged', False),
            "insiders_detected": rugcheck_data.get('insiders_detected', 0),
            "mint_authority": rugcheck_data.get('mint_authority'),
            "freeze_authority": rugcheck_data.get('freeze_authority'),
            "rugcheck_full": rugcheck_data  # Full rugcheck data for comprehensive analysis
        }
        
        # Run parallel AI analysis with different specialized models
        print(f"ü§ñ Running AI analysis with real Groq models for {token_address}")
        
        # Process uploaded chart if provided
        uploaded_chart_result = None
        if uploaded_chart:
            uploaded_chart_result = process_uploaded_chart(uploaded_chart)
            print(f"üìà Processing uploaded chart: {uploaded_chart['filename']}")
        
        # Visualization Analysis (Llama-4-Maverick Model) - FIRST to inform technical analysis
        # Only run if user uploaded a chart
        visualization_analysis = None
        if uploaded_chart_result and uploaded_chart_result.get('success'):
            visualization_analysis = call_groq_visualization_analysis(client, market_data, uploaded_chart_result)
        
        # Technical Analysis (DeepSeek R1 Reasoning Model) - Enhanced by visual analysis
        technical_analysis = call_groq_technical_analysis(client, market_data, visualization_analysis)
        
        # Market Insights (Llama 3.3 Insights Model)
        ml_insights = call_groq_insights_analysis(client, market_data)
        
        # Deep Mathematical Analysis (Moonshot Kimi-K2 Model)
        mathematical_analysis = call_groq_mathematical_analysis(client, market_data)
        
        # Generate overall signal and confidence based on AI responses
        overall_signal, confidence = analyze_ai_responses(technical_analysis, ml_insights, visualization_analysis, mathematical_analysis)
        
        # Calculate price targets based on AI recommendations
        entry_target, exit_target = calculate_ai_price_targets(current_price, technical_analysis, market_data)
        
        # Prepare analysis data for recommendation calculation
        analysis_data = {
            "overallSignal": overall_signal,
            "confidence": confidence,
            "technicalAnalysis": technical_analysis,
            "visualizationAnalysis": visualization_analysis,
            "currentPrice": current_price
        }
        
        # Calculate recommended exit target
        recommended_exit_target = calculate_recommended_exit_target(analysis_data)
        
        return {
            "overallSignal": overall_signal,
            "confidence": confidence,
            "technicalAnalysis": technical_analysis,
            "mlInsights": ml_insights,
            "visualizationAnalysis": visualization_analysis,
            "mathematicalAnalysis": mathematical_analysis,
            "uploadedChart": uploaded_chart_result,
            "entryTarget": entry_target,
            "exitTarget": exit_target,
            "recommendedExitTarget": recommended_exit_target,
            "riskScore": calculate_risk_score(token_stats),
            "currentPrice": current_price,
            "tokenName": token_stats.get('rugcheck', {}).get('token_name', ''),
            "tokenSymbol": token_stats.get('rugcheck', {}).get('token_symbol', ''),
            "analysisModels": ["DeepSeek R1 (Groq)", "QwQ-32B (Groq)", "Llama 3.3 (Groq)", "Llama-4-Maverick (Groq)", "Moonshot Kimi-K2 (Groq)"],
            "timestamp": time.time()
        }
        
    except Exception as e:
        print(f"Error in AI analysis: {e}")
        print("Falling back to simulated analysis")
        return run_simulated_ai_analysis(token_address)

def call_groq_technical_analysis(client, market_data, visual_analysis=None):
    """Call DeepSeek R1 for technical analysis"""
    try:
        # DeepSeek R1 for technical analysis and reasoning
        # Create base market data
        base_data = f"""Token Address: {market_data['token_address']}
Current Price: ${market_data['current_price']:.6f}
24h Price Change: {market_data['price_change_24h']:.2f}%
24h Volume: ${market_data['volume_24h']:,.0f}
Liquidity: ${market_data['liquidity']:,.0f}
Market Cap: ${market_data['market_cap']:,.0f}
24h Transactions - Buys: {market_data['transactions_24h'].get('buys', 0)} | Sells: {market_data['transactions_24h'].get('sells', 0)}"""

        if visual_analysis:
            # Enhanced prompt when visual analysis is available
            system_content = "You are an expert technical analyst. Create concise, actionable summaries based on detailed visual chart analysis. Focus on the most important trading insights and recommendations."
            user_content = f"""Create a concise technical summary based on this detailed visual chart analysis:

{base_data}

DETAILED VISUAL CHART ANALYSIS (from Llama-4-Maverick):
{visual_analysis}

Based on the detailed visual analysis above, provide this CONCISE SUMMARY:

**üìä Technical Summary**: 2-3 sentences combining key price action and visual patterns
**üéØ Key Levels**: Most important support/resistance levels identified in visual analysis with specific price targets
**üìà Trading Outlook**: Clear BUY/SELL/HOLD with specific reasoning from chart patterns
**‚ö†Ô∏è Risk Factors**: Main risks identified from visual chart analysis

CRITICAL: If recommending BUY/SELL, specify which resistance level percentage (5%, 10%, 15%, or 20% above current price) would be the easiest to break based on chart patterns, volume profile, and historical price action.

Keep this summary short and actionable - the detailed visual analysis is displayed separately."""
        else:
            # Standard prompt when no visual analysis available
            system_content = "You are an expert technical analyst specializing in cryptocurrency chart analysis and technical indicators. Provide detailed technical analysis based on price data and market metrics. Focus on price action patterns, support/resistance levels, volume analysis, technical indicators, and trading recommendations."
            user_content = f"""Provide technical analysis for this token:

{base_data}

Provide clean technical details in this format:

**Price Action**: Brief trend assessment with momentum direction
**Support Levels**: Volume-weighted support levels with confidence scores and specific prices
**Resistance Levels**: Volume-weighted resistance levels with confidence scores and specific prices
**Volume Analysis**: Buy/sell pressure assessment with transaction analysis
**Liquidity Analysis**: Market depth and slippage assessment
**Trading Signal**: BUY/SELL/HOLD with confidence level

CRITICAL: If recommending BUY/SELL, specify which resistance level percentage (5%, 10%, 15%, or 20% above current price of ${market_data['current_price']:.6f}) would be the easiest to break based on volume analysis, liquidity patterns, and price momentum. Consider which level has the least resistance and highest probability of successful breakout.

Keep it concise and professional."""

        response = client.chat.completions.create(
            model="deepseek-r1-distill-llama-70b",
            messages=[
                {
                    "role": "system",
                    "content": system_content
                },
                {
                    "role": "user", 
                    "content": user_content
                }
            ],
            temperature=0.1,
            max_tokens=1500
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        print(f"Error calling DeepSeek R1 for technical analysis: {e}")
        # Fallback to simulated analysis
        return generate_fallback_technical_analysis(market_data)


def call_groq_insights_analysis(client, market_data):
    """Call Llama 3.3 for market insights and summary"""
    try:
        # Llama 3.3 for insights and summary
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[
                {
                    "role": "system",
                    "content": "You are a seasoned cryptocurrency market analyst specializing in market insights, sentiment analysis, and trading psychology. Provide comprehensive market insights combining technical analysis with market sentiment and behavioral patterns."
                },
                {
                    "role": "user",
                    "content": f"""Provide comprehensive market insights for this token:

Token Address: {market_data['token_address']}
Current Price: ${market_data['current_price']:.6f}
24h Change: {market_data['price_change_24h']:.2f}%
Volume: ${market_data['volume_24h']:,.0f}
Liquidity: ${market_data['liquidity']:,.0f}
Market Cap: ${market_data['market_cap']:,.0f}
Trading Activity: {market_data['transactions_24h'].get('buys', 0)} buys, {market_data['transactions_24h'].get('sells', 0)} sells

Analyze and provide insights on:
1. Market sentiment and trading psychology indicators
2. Volume patterns and market participation analysis
3. Liquidity conditions and market depth assessment
4. Buy/sell pressure analysis and market dynamics
5. Market timing and opportunity assessment
6. Behavioral patterns and market psychology
7. Final trading recommendation with reasoning
8. Key risk factors and opportunity highlights

Synthesize all factors into actionable trading insights with clear reasoning."""
                }
            ],
            temperature=0.2,
            max_tokens=1500
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        print(f"Error calling Llama 3.3 for insights analysis: {e}")
        # Fallback to simulated analysis
        token_stats = {
            'volume_24h': market_data['volume_24h'],
            'price_change_24h': market_data['price_change_24h'],
            'transactions_24h': market_data['transactions_24h']
        }
        return generate_ml_insights(token_stats, market_data['current_price'])

def call_groq_visualization_analysis(client, market_data, uploaded_chart_result=None):
    """Call Llama-4-Maverick for visualization analysis of uploaded chart"""
    try:
        # Llama-4-Maverick for visualization and pattern recognition
        response = client.chat.completions.create(
            model="meta-llama/llama-4-maverick-17b-128e-instruct",
            messages=[
                {
                    "role": "system",
                    "content": "You are an expert in visual pattern recognition and chart visualization analysis for cryptocurrency trading. Analyze user-uploaded charts to identify price patterns, chart formations, candlestick patterns, volume patterns, and visual trading indicators. Focus on pattern recognition, trend visualization, support/resistance identification, and actionable visual trading signals."
                },
                {
                    "role": "user",
                    "content": f"""Perform comprehensive visual pattern analysis for this user-uploaded trading chart:

TOKEN DATA:
Token Address: {market_data['token_address']}
Current Price: ${market_data['current_price']:.6f}
24h Change: {market_data['price_change_24h']:.2f}%
Volume: ${market_data['volume_24h']:,.0f}
Liquidity: ${market_data['liquidity']:,.0f}
Market Cap: ${market_data['market_cap']:,.0f}
Buy/Sell Activity: {market_data['transactions_24h'].get('buys', 0)} buys, {market_data['transactions_24h'].get('sells', 0)} sells

SECURITY INDICATORS:
Risk Score: {market_data['rugcheck_score']} (Lower = Better)
LP Locked: {market_data['lp_locked_pct']:.2f}%
Holders: {market_data['total_holders']:,}
Markets: {market_data['total_markets']}

USER-UPLOADED CHART ANALYSIS:
üìà Chart Source: User-uploaded trading chart ({uploaded_chart_result.get('filename', 'Unknown')})
Chart Format: Professional trading platform (TradingView, DEXTools, etc.)
Analysis Focus: Visual patterns, technical formations, and chart-based trading signals

Analyze and provide insights on:
1. **Price Pattern Recognition**: Identify chart patterns (triangles, flags, wedges, head & shoulders)
2. **Candlestick Formations**: Analyze recent candlestick patterns and formations  
3. **Volume Pattern Analysis**: Visual volume patterns and their implications
4. **Support/Resistance Visualization**: Key visual levels and breakout patterns
5. **Trend Line Analysis**: Visual trend lines and channel patterns
6. **Visual Trading Signals**: Chart-based entry/exit signals
7. **Pattern-Based Price Targets**: Visual projection of price movements
8. **Risk Visualization**: Visual representation of risk factors from rugcheck data

Provide specific visual insights that would be visible on a trading chart. Include structured data for frontend visualization."""
                }
            ],
            temperature=0.15,
            max_tokens=1500
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        print(f"Error calling Llama-4-Maverick for visualization analysis: {e}")
        # Fallback to simulated analysis
        return f"Visual Analysis: Price trend shows {'upward' if market_data['price_change_24h'] > 0 else 'downward'} momentum with volume supporting the move. Key support at ${market_data['current_price'] * 0.95:.6f}, resistance at ${market_data['current_price'] * 1.05:.6f}."

def call_groq_mathematical_analysis(client, market_data):
    """Call Moonshot Kimi-K2 for deep mathematical analysis"""
    try:
        # Moonshot Kimi-K2 for advanced mathematical analysis
        response = client.chat.completions.create(
            model="moonshotai/kimi-k2-instruct",
            messages=[
                {
                    "role": "system",
                    "content": "You are an advanced quantitative analyst specializing in deep mathematical modeling of cryptocurrency markets. Perform sophisticated mathematical analysis using statistical models, probability theory, stochastic processes, and advanced mathematical frameworks. Focus on mathematical precision, statistical significance, and quantitative modeling."
                },
                {
                    "role": "user",
                    "content": f"""Perform deep mathematical analysis for this token:

Token Address: {market_data['token_address']}
Current Price: ${market_data['current_price']:.6f}
24h Change: {market_data['price_change_24h']:.2f}%
Volume: ${market_data['volume_24h']:,.0f}
Liquidity: ${market_data['liquidity']:,.0f}
Market Cap: ${market_data['market_cap']:,.0f}
Trading Activity: {market_data['transactions_24h'].get('buys', 0)} buys vs {market_data['transactions_24h'].get('sells', 0)} sells

SECURITY MATHEMATICS:
Rugcheck Score: {market_data['rugcheck_score']} (Mathematical risk: Lower = Better)
LP Locked: {market_data['lp_locked_pct']:.2f}%
Holder Distribution: {market_data['total_holders']:,} holders
Market Depth: {market_data['total_markets']} markets
Authority Status: {"Centralized" if market_data.get('mint_authority') or market_data.get('freeze_authority') else "Decentralized"}

Perform advanced mathematical modeling:

1. **Stochastic Price Modeling**: Calculate volatility using Geometric Brownian Motion, derive expected returns and variance
2. **Probability Distribution Analysis**: Model price movements using statistical distributions, calculate confidence intervals
3. **Risk-Return Optimization**: Mathematical risk-return ratios, Sharpe ratio calculations, maximum drawdown estimates
4. **Liquidity Mathematics**: Calculate slippage models, market impact functions, and liquidity depth analysis
5. **Statistical Arbitrage Models**: Cross-market analysis, mean reversion calculations, statistical significance tests
6. **Monte Carlo Simulations**: Price path simulations, probability of profit calculations, risk scenario modeling
7. **Mathematical Security Scoring**: Quantitative risk model incorporating rugcheck metrics with mathematical weights
8. **Algorithmic Trading Mathematics**: Optimal position sizing using Kelly criterion, expected value calculations

Provide precise mathematical formulations, statistical measures, and quantitative risk assessments with numerical precision."""
                }
            ],
            temperature=0.05,
            max_tokens=2000
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        print(f"Error calling Moonshot Kimi-K2 for mathematical analysis: {e}")
        # Fallback to simulated analysis
        volatility = abs(market_data['price_change_24h']) / 100
        return f"Mathematical Analysis: Volatility œÉ = {volatility:.4f}, Expected return Œº = {market_data['price_change_24h']/100:.4f}, Risk-adjusted return = {(market_data['price_change_24h']/100) / max(volatility, 0.01):.2f}. Optimal position size: {min(0.25 / volatility, 0.1):.3f} of portfolio."

def analyze_ai_responses(technical_analysis, ml_insights, visualization_analysis=None, mathematical_analysis=None):
    """Analyze AI responses to determine overall signal and confidence"""
    signals = []
    
    # Extract signals from technical analysis
    tech_text = technical_analysis.lower()
    if 'buy' in tech_text and 'strong' in tech_text:
        signals.append(2)
    elif 'buy' in tech_text:
        signals.append(1)
    elif 'sell' in tech_text:
        signals.append(-1)
    elif 'hold' in tech_text:
        signals.append(0)
    else:
        signals.append(0)
    
    # Extract signals from ML insights
    ml_text = ml_insights.lower()
    if 'bullish' in ml_text or 'uptrend' in ml_text:
        signals.append(1)
    elif 'bearish' in ml_text or 'downtrend' in ml_text:
        signals.append(-1)
    else:
        signals.append(0)
    
    # Extract signals from visualization analysis
    if visualization_analysis:
        viz_text = visualization_analysis.lower()
        if 'breakout' in viz_text or 'bullish pattern' in viz_text or 'upward trend' in viz_text:
            signals.append(1)
        elif 'breakdown' in viz_text or 'bearish pattern' in viz_text or 'downward trend' in viz_text:
            signals.append(-1)
        elif 'consolidation' in viz_text or 'sideways' in viz_text:
            signals.append(0)
        else:
            signals.append(0)
    
    # Extract signals from mathematical analysis
    if mathematical_analysis:
        math_text = mathematical_analysis.lower()
        if 'positive expected return' in math_text or 'favorable risk-return' in math_text:
            signals.append(1)
        elif 'negative expected return' in math_text or 'unfavorable risk-return' in math_text:
            signals.append(-1)
        elif 'optimal position size' in math_text and 'low' not in math_text:
            signals.append(0.5)  # Mathematical model suggests reasonable position
        else:
            signals.append(0)
    
    # Calculate overall signal with enhanced weighting for 5 models
    avg_signal = sum(signals) / len(signals) if signals else 0
    
    if avg_signal > 0.7:
        overall_signal = "STRONG_BUY"
        confidence = min(0.95, 0.8 + abs(avg_signal) * 0.1)
    elif avg_signal > 0.3:
        overall_signal = "BUY"
        confidence = min(0.9, 0.7 + abs(avg_signal) * 0.2)
    elif avg_signal > -0.3:
        overall_signal = "HOLD"
        confidence = 0.6 + abs(avg_signal) * 0.1
    elif avg_signal > -0.7:
        overall_signal = "SELL"
        confidence = min(0.9, 0.7 + abs(avg_signal) * 0.2)
    else:
        overall_signal = "STRONG_SELL"
        confidence = min(0.95, 0.8 + abs(avg_signal) * 0.1)
    
    return overall_signal, confidence

def calculate_ai_price_targets(current_price, technical_analysis, market_data):
    """Calculate price targets based on AI recommendations"""
    try:
        # Extract price targets from technical analysis if mentioned
        tech_text = technical_analysis.lower()
        
        # Default targets
        entry_target = current_price * 0.99  # 1% below current
        exit_target = current_price * 1.2    # 20% above current
        
        # Look for specific price targets in technical analysis
        import re
        
        # Look for support levels
        support_matches = re.findall(r'support.*?(\d+\.?\d*)', tech_text)
        if support_matches:
            try:
                support_level = float(support_matches[0])
                if support_level < current_price:
                    entry_target = support_level * 1.02  # 2% above support
            except:
                pass
        
        # Look for resistance levels  
        resistance_matches = re.findall(r'resistance.*?(\d+\.?\d*)', tech_text)
        if resistance_matches:
            try:
                resistance_level = float(resistance_matches[0])
                if resistance_level > current_price:
                    exit_target = resistance_level * 0.98  # 2% below resistance
            except:
                pass
        
        # Adjust based on price change momentum
        price_change = market_data.get('price_change_24h', 0)
        if price_change > 10:  # Strong uptrend
            exit_target = current_price * 1.3
        elif price_change < -10:  # Strong downtrend
            entry_target = current_price * 0.95
            
        return entry_target, exit_target
        
    except Exception as e:
        print(f"Error calculating price targets: {e}")
        return current_price * 0.99, current_price * 1.2

def calculate_recommended_exit_target(analysis_data):
    """Calculate AI-recommended exit target based on resistance analysis and market conditions"""
    try:
        current_price = analysis_data.get('currentPrice', 0)
        if current_price == 0:
            return {"percentage": 10, "reasoning": "Default target", "confidence": 0.5}
        
        technical_analysis = analysis_data.get('technicalAnalysis', '').lower()
        visualization_analysis = analysis_data.get('visualizationAnalysis', '').lower()
        overall_signal = analysis_data.get('overallSignal', 'HOLD')
        confidence = analysis_data.get('confidence', 0.5)
        
        # Available target options
        target_options = [5, 10, 15, 20]
        scores = {}
        
        # Score each target based on multiple factors
        for percentage in target_options:
            score = 0.5  # Base score
            target_price = current_price * (1 + percentage / 100)
            
            # Factor 1: Signal strength influence
            if overall_signal in ['BUY', 'STRONG_BUY']:
                if percentage <= 10:
                    score += 0.2  # Conservative targets get bonus for buy signals
                elif percentage >= 15:
                    score += 0.3  # Aggressive targets get bigger bonus
            elif overall_signal == 'HOLD':
                if percentage <= 10:
                    score += 0.1  # Favor conservative targets for hold
            
            # Factor 2: Confidence level influence
            if confidence > 0.8:
                if percentage >= 15:
                    score += 0.2  # High confidence allows aggressive targets
            elif confidence < 0.6:
                if percentage <= 10:
                    score += 0.1  # Low confidence favors conservative targets
            
            # Factor 3: Technical analysis resistance mentions
            if f"resistance" in technical_analysis:
                import re
                # Look for resistance levels near our target
                resistance_matches = re.findall(r'resistance.*?(\d+\.?\d*)', technical_analysis)
                for match in resistance_matches:
                    try:
                        resistance_level = float(match)
                        if abs(resistance_level - target_price) / current_price < 0.05:  # Within 5%
                            score += 0.3  # Bonus for targets near mentioned resistance
                    except:
                        pass
            
            # Factor 4: Chart pattern analysis
            pattern_bonus = 0
            if visualization_analysis:
                if "breakout" in visualization_analysis and percentage >= 15:
                    pattern_bonus += 0.2
                elif "consolidation" in visualization_analysis and percentage <= 10:
                    pattern_bonus += 0.2
                elif "triangle" in visualization_analysis:
                    if percentage == 10 or percentage == 15:
                        pattern_bonus += 0.15  # Triangle patterns often target 10-15%
            
            score += pattern_bonus
            scores[percentage] = score
        
        # Find the highest scoring target
        recommended_percentage = max(scores.keys(), key=lambda k: scores[k])
        recommended_score = scores[recommended_percentage]
        
        # Generate reasoning
        reasoning_parts = []
        if overall_signal in ['BUY', 'STRONG_BUY']:
            reasoning_parts.append(f"{overall_signal} signal supports higher targets")
        if confidence > 0.8:
            reasoning_parts.append("High confidence analysis")
        elif confidence < 0.6:
            reasoning_parts.append("Conservative target due to lower confidence")
        
        if "resistance" in technical_analysis:
            reasoning_parts.append("Aligns with identified resistance levels")
        if "breakout" in visualization_analysis:
            reasoning_parts.append("Chart pattern suggests breakout potential")
        elif "consolidation" in visualization_analysis:
            reasoning_parts.append("Consolidation pattern favors conservative exit")
        
        if not reasoning_parts:
            reasoning_parts.append("Balanced risk-reward ratio")
        
        reasoning = " ‚Ä¢ ".join(reasoning_parts[:3])  # Max 3 reasons
        
        return {
            "percentage": recommended_percentage,
            "price": current_price * (1 + recommended_percentage / 100),
            "reasoning": reasoning,
            "confidence": min(recommended_score, 0.95)  # Cap at 95%
        }
        
    except Exception as e:
        print(f"Error calculating recommended exit target: {e}")
        return {
            "percentage": 10,
            "reasoning": "Default conservative target",
            "confidence": 0.5
        }

def calculate_fibonacci_levels(current_price, price_change_24h):
    """Calculate Fibonacci retracement levels based on recent price action"""
    # Estimate recent high/low based on 24h change
    if price_change_24h > 0:
        recent_high = current_price
        recent_low = current_price / (1 + price_change_24h/100)
    else:
        recent_high = current_price / (1 + price_change_24h/100) 
        recent_low = current_price
    
    price_range = recent_high - recent_low
    
    # Fibonacci retracement levels
    fib_levels = {
        'support_23.6': recent_low + (price_range * 0.236),
        'support_38.2': recent_low + (price_range * 0.382),
        'support_50.0': recent_low + (price_range * 0.500),
        'support_61.8': recent_low + (price_range * 0.618),
        'resistance_61.8': recent_high - (price_range * 0.382),
        'resistance_78.6': recent_high - (price_range * 0.214)
    }
    
    return fib_levels

def calculate_volume_weighted_levels(current_price, volume_24h, transactions_24h):
    """Calculate support/resistance levels weighted by volume and transaction data"""
    buys = transactions_24h.get('buys', 0)
    sells = transactions_24h.get('sells', 0)
    total_txns = buys + sells
    
    if total_txns == 0:
        # Fallback to simple percentage levels
        return {
            'support_1': {'price': current_price * 0.97, 'confidence': 0.3},
            'support_2': {'price': current_price * 0.94, 'confidence': 0.2},
            'resistance_1': {'price': current_price * 1.03, 'confidence': 0.3},
            'resistance_2': {'price': current_price * 1.06, 'confidence': 0.2}
        }
    
    # Volume-weighted calculations
    buy_volume_weight = buys / total_txns if total_txns > 0 else 0.5
    sell_volume_weight = sells / total_txns if total_txns > 0 else 0.5
    
    # Support levels (stronger with more buy volume)
    support_1_price = current_price * (0.97 - (buy_volume_weight * 0.01))
    support_2_price = current_price * (0.94 - (buy_volume_weight * 0.02))
    
    # Resistance levels (stronger with more sell volume)  
    resistance_1_price = current_price * (1.03 + (sell_volume_weight * 0.01))
    resistance_2_price = current_price * (1.06 + (sell_volume_weight * 0.02))
    
    # Confidence scores based on volume and transaction count
    volume_factor = min(volume_24h / 1000000, 1.0)  # Normalize to 0-1 scale
    txn_factor = min(total_txns / 1000, 1.0)  # Normalize to 0-1 scale
    base_confidence = (volume_factor + txn_factor) / 2
    
    return {
        'support_1': {
            'price': support_1_price, 
            'confidence': min(base_confidence + buy_volume_weight * 0.3, 0.9)
        },
        'support_2': {
            'price': support_2_price,
            'confidence': min(base_confidence + buy_volume_weight * 0.2, 0.8)
        },
        'resistance_1': {
            'price': resistance_1_price,
            'confidence': min(base_confidence + sell_volume_weight * 0.3, 0.9)
        },
        'resistance_2': {
            'price': resistance_2_price,
            'confidence': min(base_confidence + sell_volume_weight * 0.2, 0.8)
        }
    }

def generate_fallback_technical_analysis(market_data):
    """Generate enhanced technical analysis with volume-weighted levels"""
    current_price = market_data['current_price']
    volume_24h = market_data.get('volume_24h', 0)
    liquidity = market_data.get('liquidity', 0)
    price_change = market_data.get('price_change_24h', 0)
    buys = market_data.get('transactions_24h', {}).get('buys', 0)
    sells = market_data.get('transactions_24h', {}).get('sells', 0)
    
    # Calculate volume-weighted support/resistance levels
    levels = calculate_volume_weighted_levels(current_price, volume_24h, market_data.get('transactions_24h', {}))
    
    # Calculate Fibonacci levels for additional context
    fib_levels = calculate_fibonacci_levels(current_price, price_change)
    
    # Determine trend and signal
    trend = "bullish" if price_change > 2 else "bearish" if price_change < -2 else "sideways"
    signal = "BUY" if price_change > 5 and volume_24h > 50000 else "SELL" if price_change < -10 else "HOLD"
    
    # Buy/sell pressure analysis
    total_txns = buys + sells
    buy_pressure = "Strong" if buys > sells * 1.5 else "Weak" if sells > buys * 1.5 else "Balanced"
    
    # Format analysis with enhanced levels
    analysis = f"""**Price Action**: {trend.capitalize()} momentum with {abs(price_change):.2f}% 24h change

**Support Levels**: ${levels['support_1']['price']:.6f} (confidence: {levels['support_1']['confidence']:.1%}), ${levels['support_2']['price']:.6f} (confidence: {levels['support_2']['confidence']:.1%})

**Resistance Levels**: ${levels['resistance_1']['price']:.6f} (confidence: {levels['resistance_1']['confidence']:.1%}), ${levels['resistance_2']['price']:.6f} (confidence: {levels['resistance_2']['confidence']:.1%})

**Volume Analysis**: {buy_pressure} buy pressure ({buys} buys vs {sells} sells) with ${volume_24h:,.0f} 24h volume

**Liquidity Analysis**: ${liquidity:,.0f} liquidity depth, {"High" if liquidity > 1000000 else "Medium" if liquidity > 100000 else "Low"} slippage risk

**Trading Signal**: {signal} (Confidence: {60 + abs(price_change) * 2:.0f}%)"""
    
    return analysis

def capture_dextools_chart(token_address):
    """Capture DEXTools chart screenshot for visual analysis"""
    try:
        # Ensure chromedriver is installed
        chromedriver_autoinstaller.install()
        
        # Setup Chrome options for headless operation
        chrome_options = Options()
        chrome_options.add_argument('--headless')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--window-size=1920,1080')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--disable-extensions')
        
        # Initialize driver
        driver = webdriver.Chrome(options=chrome_options)
        
        try:
            # Navigate to DEXTools chart page
            dextools_url = f"https://www.dextools.io/app/en/solana/pair-explorer/{token_address}"
            print(f"üì∏ Capturing DEXTools chart for {token_address}")
            driver.get(dextools_url)
            
            # Wait for chart to load (increased wait time for chart data)
            WebDriverWait(driver, 15).until(
                EC.presence_of_element_located((By.CLASS_NAME, "chart-container"))
            )
            
            # Wait additional time for price data to load
            time.sleep(8)
            
            # Generate filename with timestamp
            timestamp = int(time.time())
            filename = f"chart_{token_address}_{timestamp}.png"
            filepath = f"static/charts/{filename}"
            
            # Take screenshot
            driver.save_screenshot(filepath)
            
            # Optimize image size
            with Image.open(filepath) as img:
                # Resize if too large
                if img.width > 1920 or img.height > 1080:
                    img.thumbnail((1920, 1080), Image.Resampling.LANCZOS)
                    img.save(filepath, optimize=True, quality=85)
            
            print(f"‚úÖ Chart screenshot saved: {filepath}")
            return {
                'success': True,
                'filename': filename,
                'filepath': filepath,
                'url': f"/static/charts/{filename}",
                'timestamp': timestamp
            }
            
        finally:
            driver.quit()
            
    except Exception as e:
        print(f"‚ùå Error capturing DEXTools chart: {e}")
        
        # Fallback: Try DexScreener chart link
        try:
            dexscreener_url = f"https://dexscreener.com/solana/{token_address}"
            return {
                'success': False,
                'error': str(e),
                'fallback_url': dexscreener_url,
                'message': f"Chart screenshot failed, view chart at: {dexscreener_url}"
            }
        except:
            return {
                'success': False,
                'error': str(e),
                'message': "Chart screenshot failed and no fallback available"
            }


def generate_ml_insights(token_stats, current_price):
    """Generate ML insights using Llama 3.3 model simulation"""
    buys = token_stats.get('transactions_24h', {}).get('buys', 0)
    sells = token_stats.get('transactions_24h', {}).get('sells', 0)
    buy_ratio = buys / (buys + sells) if (buys + sells) > 0 else 0.5
    
    analysis = f"""**ML Model Insights (Llama 3.3 + Traditional TA + HMM)**

**Market Sentiment**: {"Bullish" if buy_ratio > 0.6 else "Bearish" if buy_ratio < 0.4 else "Neutral"} with {buy_ratio:.1%} buy ratio ({buys} buys vs {sells} sells).

**Hidden Markov Model Regime**: {"BULL" if buy_ratio > 0.6 and token_stats.get('price_change_24h', 0) > 5 else "BEAR" if buy_ratio < 0.4 and token_stats.get('price_change_24h', 0) < -5 else "SIDEWAYS"} market detected.

**ML Pattern Recognition**:
- Trend strength: {abs(token_stats.get('price_change_24h', 0)) * 2:.1f}/100
- Volume momentum: {"Increasing" if token_stats.get('volume_24h', 0) > 100000 else "Decreasing"}
- Breakout probability: {min(85, max(15, 50 + token_stats.get('price_change_24h', 0) * 3)):.0f}%

**Traditional TA Indicators**:
- 20-period EMA: ${current_price * 0.99:.6f}
- Bollinger Bands: ${current_price * 0.95:.6f} - ${current_price * 1.05:.6f}
- Stochastic: {min(90, max(10, 50 + token_stats.get('price_change_24h', 0) * 2)):.0f}%

**ML Prediction**: {"Uptrend continuation" if buy_ratio > 0.55 and token_stats.get('price_change_24h', 0) > 0 else "Trend reversal likely" if buy_ratio < 0.45 else "Consolidation expected"} based on 20+ indicators."""
    
    return analysis

def calculate_overall_signal(technical_analysis, ml_insights):
    """Calculate overall trading signal and confidence from all analyses"""
    # Count bullish/bearish signals from each analysis
    signals = []
    
    if "BUY" in technical_analysis:
        signals.append(1)
    elif "SELL" in technical_analysis:
        signals.append(-1)
    else:
        signals.append(0)
    
    if "Bullish" in ml_insights or "Uptrend" in ml_insights:
        signals.append(1)
    elif "Bearish" in ml_insights or "reversal" in ml_insights:
        signals.append(-1)
    else:
        signals.append(0)
    
    avg_signal = sum(signals) / len(signals)
    
    if avg_signal > 0.3:
        overall_signal = "BUY"
        confidence = min(0.95, 0.6 + abs(avg_signal) * 0.3)
    elif avg_signal < -0.3:
        overall_signal = "SELL"
        confidence = min(0.95, 0.6 + abs(avg_signal) * 0.3)
    else:
        overall_signal = "HOLD"
        confidence = 0.5 + abs(avg_signal) * 0.2
    
    return overall_signal, confidence

def calculate_risk_score(token_stats):
    """Calculate numerical risk score (0-1, where 1 is highest risk) using rugcheck data"""
    liquidity = token_stats.get('liquidity', 0)
    market_cap = token_stats.get('market_cap', 0)
    price_change = abs(token_stats.get('price_change_24h', 0))
    rugcheck_data = token_stats.get('rugcheck', {})
    
    # Rugcheck risk factors (primary factor)
    rugcheck_score = rugcheck_data.get('score', 999)
    if rugcheck_data.get('rugged', False):
        rugcheck_risk = 1.0  # Maximum risk for rugged tokens
    elif rugcheck_score <= 1:
        rugcheck_risk = 0.1  # Very low risk
    elif rugcheck_score <= 5:
        rugcheck_risk = 0.3  # Low risk
    elif rugcheck_score <= 10:
        rugcheck_risk = 0.6  # Moderate risk
    else:
        rugcheck_risk = 0.9  # High risk
    
    # Secondary risk factors
    liquidity_risk = max(0, 1 - (liquidity / 1000000))  # Higher risk for low liquidity
    market_cap_risk = max(0, 1 - (market_cap / 10000000))  # Higher risk for low market cap
    volatility_risk = min(1, price_change / 50)  # Higher risk for high volatility
    
    # LP lock risk factor
    lp_locked = rugcheck_data.get('lp_locked_pct', 0)
    lp_risk = max(0, 1 - (lp_locked / 80))  # Higher risk if less than 80% locked
    
    # Weighted average with rugcheck as primary factor
    risk_score = (rugcheck_risk * 0.5 + liquidity_risk * 0.2 + market_cap_risk * 0.15 + volatility_risk * 0.1 + lp_risk * 0.05)
    return min(1.0, max(0.0, risk_score))

def run_simulated_ai_analysis(token_address, uploaded_chart=None):
    """Fallback simulated AI analysis when Groq fails"""
    try:
        # Get token data for simulation
        token_stats = get_comprehensive_token_data(token_address)
        price_data = get_live_price(token_address)
        
        if not price_data:
            raise Exception("Could not fetch price data for simulation")
        
        current_price = price_data['priceUsd']
        
        # Generate simulated analyses
        technical_analysis = generate_fallback_technical_analysis({
            'current_price': current_price,
            'volume_24h': token_stats.get('volume_24h', 0),
            'liquidity': token_stats.get('liquidity', 0),
            'price_change_24h': token_stats.get('price_change_24h', 0)
        })
        
        ml_insights = generate_ml_insights(token_stats, current_price)
        
        # Calculate overall signal using simulated responses
        overall_signal, confidence = calculate_overall_signal(technical_analysis, ml_insights)
        
        # Calculate price targets
        entry_target, exit_target = calculate_ai_price_targets(current_price, technical_analysis, {
            'price_change_24h': token_stats.get('price_change_24h', 0)
        })
        
        # Prepare analysis data for recommendation calculation
        analysis_data = {
            "overallSignal": overall_signal,
            "confidence": confidence,
            "technicalAnalysis": technical_analysis,
            "visualizationAnalysis": "",
            "currentPrice": current_price
        }
        
        # Calculate recommended exit target
        recommended_exit_target = calculate_recommended_exit_target(analysis_data)
        
        return {
            "overallSignal": overall_signal,
            "confidence": confidence,
            "technicalAnalysis": technical_analysis,
            "mlInsights": ml_insights,
            "entryTarget": entry_target,
            "exitTarget": exit_target,
            "recommendedExitTarget": recommended_exit_target,
            "riskScore": calculate_risk_score(token_stats),
            "currentPrice": current_price,
            "tokenName": token_stats.get('rugcheck', {}).get('token_name', ''),
            "tokenSymbol": token_stats.get('rugcheck', {}).get('token_symbol', ''),
            "analysisModels": ["Simulated DeepSeek R1", "Simulated QwQ-32B", "Simulated Llama 3.3"],
            "timestamp": time.time()
        }
        
    except Exception as e:
        print(f"Error in simulated analysis: {e}")
        # Return basic fallback
        return {
            "overallSignal": "HOLD",
            "confidence": 0.5,
            "technicalAnalysis": "Unable to complete analysis",
            "mlInsights": "Unable to generate insights",
            "entryTarget": 0,
            "exitTarget": 0,
            "recommendedExitTarget": {"percentage": 10, "reasoning": "Default conservative target", "confidence": 0.5},
            "riskScore": 0.5,
            "currentPrice": 0,
            "analysisModels": ["Fallback"],
            "timestamp": time.time()
        }

def generate_ai_trading_signals(token_address):
    """Generate real-time AI trading signals for dynamic trading"""
    try:
        # Get current data
        token_stats = get_comprehensive_token_data(token_address)
        price_data = get_live_price(token_address)
        
        if not price_data:
            raise Exception("Could not fetch price data")
        
        current_price = price_data['priceUsd']
        price_change = token_stats.get('price_change_24h', 0)
        
        # Generate dynamic trading parameters
        recommended_buy_price = current_price * (0.97 if price_change > 5 else 0.99)
        recommended_sell_price = current_price * (1.20 if price_change > 10 else 1.15)
        recommended_stop_loss = max(5, min(30, abs(price_change) + 10))
        
        # Signal strength
        signal_strength = "STRONG" if abs(price_change) > 15 else "MODERATE" if abs(price_change) > 5 else "WEAK"
        
        return {
            "current_price": current_price,
            "recommended_buy_price": recommended_buy_price,
            "recommended_sell_price": recommended_sell_price,
            "recommended_stop_loss": recommended_stop_loss,
            "signal_strength": signal_strength,
            "reasoning": f"Based on {price_change:.2f}% 24h change and current market conditions",
            "confidence": min(0.95, 0.5 + abs(price_change) / 50),
            "last_updated": datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"Error generating AI signals: {e}")
        raise e

def fetch_chart_data(token_address, timeframe='1h', limit=100):
    """Fetch OHLCV chart data from DexScreener - Jupiter script approach"""
    try:
        print(f"Fetching chart data for {token_address} using Jupiter script approach")
        
        # Use Jupiter script approach: fetch token pairs from DexScreener
        url = f"https://api.dexscreener.com/latest/dex/tokens/{token_address}"
        response = requests.get(url, timeout=10)
        
        if response.status_code != 200:
            print(f"DexScreener API failed with status {response.status_code}")  
            return generate_fallback_chart_data(token_address, limit)
        
        data = response.json()
        pairs = data.get('pairs', [])
        
        if not pairs or len(pairs) == 0:
            print(f"No pairs found for token {token_address}")
            return generate_fallback_chart_data(token_address, limit)
        
        # Jupiter script filtering: find valid pair with chainId === 'solana' and dexId === 'raydium'
        valid_pair = None
        for pair in pairs:
            if (pair.get('chainId') == 'solana' and 
                pair.get('dexId') == 'raydium' and 
                pair.get('priceUsd')):
                valid_pair = pair
                break
        
        # Fallback: find any Solana pair if no Raydium pair found
        if not valid_pair:
            for pair in pairs:
                if pair.get('chainId') == 'solana' and pair.get('priceUsd'):
                    valid_pair = pair
                    break
        
        # Final fallback: use first pair with valid price
        if not valid_pair:
            for pair in pairs:
                if pair.get('priceUsd'):
                    valid_pair = pair
                    break
        
        if not valid_pair:
            print(f"No valid pair found for token {token_address}")
            return generate_fallback_chart_data(token_address, limit)
        
        # Extract real market data (like Jupiter script)
        current_price = float(valid_pair.get('priceUsd', 0))
        
        if current_price <= 0:
            print(f"Invalid price for token {token_address}: {current_price}")
            return generate_fallback_chart_data(token_address, limit)
        
        print(f"Jupiter-style price fetch: ${current_price} for {token_address} from {valid_pair.get('dexId')}")
        
        # Get real market metrics
        price_change_24h = float(valid_pair.get('priceChange', {}).get('h24', 0))
        volume_24h = float(valid_pair.get('volume', {}).get('h24', 0))
        liquidity = float(valid_pair.get('liquidity', {}).get('usd', 0))
        
        # Store current price for building real OHLCV history over time
        store_price_point(token_address, current_price, volume_24h)
        
        # Generate realistic chart data based on real current market conditions
        chart_data = generate_market_based_chart_data(
            current_price, price_change_24h, volume_24h, liquidity, limit
        )
        
        print(f"Generated {len(chart_data)} chart points based on real market data for {token_address}")
        return chart_data
        
    except Exception as e:
        print(f"Error fetching Jupiter-style chart data for {token_address}: {e}")
        return generate_fallback_chart_data(token_address, limit)

# Global storage for real price history (in production, use Redis or database)
price_history = {}

def store_price_point(token_address, price, volume):
    """Store current price point to build real OHLCV history over time"""
    try:
        current_time = int(time.time())
        
        if token_address not in price_history:
            price_history[token_address] = []
        
        # Add current price point
        price_history[token_address].append({
            'timestamp': current_time,
            'price': price,
            'volume': volume
        })
        
        # Keep only last 200 points (about 8 days if updated every hour)
        if len(price_history[token_address]) > 200:
            price_history[token_address] = price_history[token_address][-200:]
            
        print(f"Stored price point for {token_address}: ${price} (total points: {len(price_history[token_address])})")
        
    except Exception as e:
        print(f"Error storing price point: {e}")

def generate_market_based_chart_data(current_price, price_change_24h, volume_24h, liquidity, limit=100):
    """Generate realistic chart data based on actual current market conditions"""
    try:
        import random
        import math
        
        chart_data = []
        current_time = int(time.time())
        time_interval = 3600  # 1 hour intervals
        
        # Calculate more realistic price progression based on market conditions
        price_24h_ago = current_price / (1 + (price_change_24h / 100)) if price_change_24h != 0 else current_price
        
        # Determine volatility based on liquidity and volume
        base_volatility = 0.02  # 2% base volatility
        
        # Lower liquidity = higher volatility
        liquidity_factor = max(0.5, min(2.0, 500000 / max(liquidity, 10000)))
        
        # Higher volume = higher volatility (more trading activity)
        volume_factor = max(0.8, min(1.5, volume_24h / 100000)) if volume_24h > 0 else 1.0
        
        # Calculate final volatility
        volatility = base_volatility * liquidity_factor * volume_factor
        
        print(f"Market-based volatility: {volatility:.4f} (liquidity: ${liquidity:,.0f}, volume: ${volume_24h:,.0f})")
        
        for i in range(limit):
            # Time going backwards from now
            timestamp = current_time - (i * time_interval)
            
            # Calculate position in 24h progression (0 = 24h ago, 1 = now)
            progress = (limit - i - 1) / (limit - 1) if limit > 1 else 0
            
            # Price progression from 24h ago to current
            base_price = price_24h_ago + (current_price - price_24h_ago) * progress
            
            # Add market-driven volatility patterns
            trend_component = math.sin(i / 20) * volatility * 0.3  # Longer trend waves
            short_term_noise = math.sin(i / 5) * volatility * 0.2   # Short-term fluctuations
            random_noise = random.uniform(-volatility, volatility) * 0.5
            
            # Combine all price factors
            price_variation = trend_component + short_term_noise + random_noise
            adjusted_price = base_price * (1 + price_variation)
            
            # Ensure price stays positive and reasonable
            adjusted_price = max(adjusted_price, current_price * 0.1)
            adjusted_price = min(adjusted_price, current_price * 10)
            
            # Generate realistic OHLCV for this period
            micro_volatility = volatility * 0.1  # Small variations within the hour
            
            open_price = adjusted_price * (1 + random.uniform(-micro_volatility, micro_volatility))
            close_price = adjusted_price * (1 + random.uniform(-micro_volatility, micro_volatility))
            
            # High and low should respect open/close but add some range
            high_price = max(open_price, close_price) * (1 + random.uniform(0, micro_volatility * 2))
            low_price = min(open_price, close_price) * (1 - random.uniform(0, micro_volatility * 2))
            
            # Volume based on 24h volume with realistic variation
            if volume_24h > 0:
                base_hourly_volume = volume_24h / 24
                volume_variation = random.uniform(0.3, 2.5)  # Wide volume variation is realistic
                hourly_volume = base_hourly_volume * volume_variation
            else:
                hourly_volume = random.uniform(1000, 10000)  # Default volume range
            
            chart_data.append({
                "timestamp": timestamp,
                "open": round(open_price, 8),
                "high": round(high_price, 8), 
                "low": round(low_price, 8),
                "close": round(close_price, 8),
                "volume": round(hourly_volume, 2)
            })
        
        # Sort by timestamp (oldest first)
        chart_data.sort(key=lambda x: x['timestamp'])
        return chart_data
        
    except Exception as e:
        print(f"Error generating market-based chart data: {e}")
        return generate_fallback_chart_data("", limit)

def generate_realistic_chart_data(current_price, price_change_24h, volume_24h, limit=100):
    """Generate realistic-looking historical data based on current market data"""
    import random
    import math
    
    chart_data = []
    current_time = int(time.time())
    
    # Calculate the price 24h ago based on 24h change
    price_24h_ago = current_price / (1 + (price_change_24h / 100)) if price_change_24h != 0 else current_price
    
    # Create a price progression from 24h ago to now
    time_interval = 3600  # 1 hour intervals
    
    for i in range(limit):
        # Time going backwards from now
        timestamp = current_time - (i * time_interval)
        
        # Calculate position in the 24h progression (0 = 24h ago, 1 = now)
        progress = (limit - i - 1) / (limit - 1) if limit > 1 else 0
        
        # Base price progression from 24h ago to current price
        base_price = price_24h_ago + (current_price - price_24h_ago) * progress
        
        # Add some realistic volatility
        volatility = abs(price_change_24h) * 0.02  # 2% of the daily change as volatility
        price_variation = random.uniform(-volatility, volatility) / 100
        
        # Add some trend and noise
        trend_noise = math.sin(i / 10) * 0.005  # Small wave pattern
        random_noise = random.uniform(-0.01, 0.01)  # Small random variation
        
        adjusted_price = base_price * (1 + price_variation + trend_noise + random_noise)
        
        # Ensure price doesn't go negative
        adjusted_price = max(adjusted_price, current_price * 0.01)
        
        # Generate OHLCV data for this time period
        open_price = adjusted_price * random.uniform(0.995, 1.005)
        close_price = adjusted_price * random.uniform(0.995, 1.005)
        high_price = max(open_price, close_price) * random.uniform(1.002, 1.02)
        low_price = min(open_price, close_price) * random.uniform(0.98, 0.998)
        
        # Generate volume based on 24h volume with some variation
        avg_hourly_volume = volume_24h / 24 if volume_24h > 0 else 1000
        volume = avg_hourly_volume * random.uniform(0.3, 2.0)
        
        chart_data.append({
            "timestamp": timestamp,
            "open": round(open_price, 8),
            "high": round(high_price, 8),
            "low": round(low_price, 8),
            "close": round(close_price, 8),
            "volume": round(volume, 2)
        })
    
    # Sort by timestamp (oldest first for chart)
    chart_data.sort(key=lambda x: x['timestamp'])
    return chart_data

def generate_fallback_chart_data(token_address, limit=100):
    """Generate fallback chart data when API fails"""
    try:
        # Try to get current price for fallback
        price_data = get_live_price(token_address)
        current_price = price_data['priceUsd'] if price_data else 0.001
        
        return generate_realistic_chart_data(current_price, 0, 10000, limit)
    except:
        # Ultimate fallback
        return []

def create_modified_bot_script(dex_type='jupiter'):
    """Create a temporary bot script with current configuration for specified DEX"""
    
    # Select appropriate script based on DEX type
    if dex_type == 'raydium':
        original_script_path = Path(__file__).parent / 'limitorder-raydium.js'
        script_prefix = 'raydium'
    else:
        original_script_path = Path(__file__).parent / 'limitorder-jupitor.js'
        script_prefix = 'jupitor'
    
    with open(original_script_path, 'r') as f:
        script_content = f.read()
    
    # Replace the hardcoded values with our configuration (identical for both scripts now)
    script_content = script_content.replace(
        "{ mint: '5UUH9RTDiSpq6HKS6bp4NdU9PNJpXRXuiw6ShBTBhgH2', name: 'TROLL' }",
        f"{{ mint: '{bot_config['token_address']}', name: '{bot_config['token_symbol']}' }}"
    )
    
    script_content = script_content.replace(
        "TARGET_BUY_PRICE_USD   = 0.018",
        f"TARGET_BUY_PRICE_USD   = {bot_config['target_buy_price']}"
    )
    
    script_content = script_content.replace(
        "TARGET_SELL_PRICE_USD  = 0.02",
        f"TARGET_SELL_PRICE_USD  = {bot_config['target_sell_price']}"
    )
    
    script_content = script_content.replace(
        "STOP_LOSS_PERCENTAGE   = 40",
        f"STOP_LOSS_PERCENTAGE   = {bot_config['stop_loss_percentage']}"
    )
    
    script_content = script_content.replace(
        "AMOUNT_TO_TRADE        = 0.1",
        f"AMOUNT_TO_TRADE        = {bot_config['amount_to_trade']}"
    )
    
    script_content = script_content.replace(
        "SLIPPAGE_BPS           = 200",
        f"SLIPPAGE_BPS           = {bot_config['slippage_bps']}"
    )
    
    # Write the modified script to a temporary file
    temp_script_path = Path(__file__).parent / f'limitorder-{script_prefix}-configured.js'
    with open(temp_script_path, 'w') as f:
        f.write(script_content)
    
    return temp_script_path

def create_liquidation_script(dex_type, token_address):
    """Create a temporary liquidation script for immediate token selling"""
    try:
        # Create a simple liquidation script that sells all tokens immediately
        if dex_type == 'jupiter':
            script_content = f'''
import {{ Connection, Keypair, VersionedTransaction, PublicKey }} from '@solana/web3.js';
import {{ NATIVE_MINT }} from '@solana/spl-token';
import fetch from 'cross-fetch';
import {{ Wallet }} from '@project-serum/anchor';
import bs58 from 'bs58';
import dotenv from 'dotenv';
import {{ connection, owner, fetchTokenAccountData }} from './config.js';

dotenv.config();

const TOKEN_ADDRESS = '{token_address}';
const SLIPPAGE_BPS = 1000; // Higher slippage for emergency liquidation

async function liquidatePosition() {{
    try {{
        console.log('üîª Starting emergency liquidation...');
        
        // Get token accounts
        const {{ tokenAccounts }} = await fetchTokenAccountData();
        const tokenAccount = tokenAccounts.find(acc => acc.mint.toBase58() === TOKEN_ADDRESS);
        
        if (!tokenAccount || tokenAccount.amount <= 0) {{
            console.log('‚ùå No token balance found for liquidation');
            return;
        }}
        
        const tokenBalance = tokenAccount.amount;
        console.log(`üí∞ Token balance: ${{tokenBalance}}`);
        
        // Get Jupiter quote for selling all tokens
        const quoteUrl = `https://quote-api.jup.ag/v6/quote` +
            `?inputMint=${{TOKEN_ADDRESS}}` +
            `&outputMint=${{NATIVE_MINT.toBase58()}}` +
            `&amount=${{tokenBalance}}` +
            `&slippageBps=${{SLIPPAGE_BPS}}` +
            `&onlyDirectRoutes=true`;
        
        console.log('üìä Getting liquidation quote...');
        const quoteResponse = await fetch(quoteUrl);
        const quoteData = await quoteResponse.json();
        
        if (!quoteData.outAmount) {{
            throw new Error('Failed to get liquidation quote');
        }}
        
        console.log(`üí± Selling ${{tokenBalance}} tokens for ~${{(quoteData.outAmount / 1e9).toFixed(4)}} SOL`);
        
        // Get swap transaction
        const swapResponse = await fetch('https://quote-api.jup.ag/v6/swap', {{
            method: 'POST',
            headers: {{ 'Content-Type': 'application/json' }},
            body: JSON.stringify({{
                quoteResponse: quoteData,
                userPublicKey: owner.publicKey.toString(),
                wrapAndUnwrapSol: true,
                computeUnitPriceMicroLamports: 'auto'
            }})
        }});
        
        const swapData = await swapResponse.json();
        const txBuf = Buffer.from(swapData.swapTransaction, 'base64');
        const tx = VersionedTransaction.deserialize(txBuf);
        tx.sign([owner]);
        
        // Execute liquidation
        console.log('‚ö° Executing liquidation transaction...');
        const signature = await connection.sendTransaction(tx);
        await connection.confirmTransaction(signature, 'confirmed');
        
        console.log(`‚úÖ Liquidation successful! Signature: ${{signature}}`);
        console.log(`üéØ Position closed for token: ${{TOKEN_ADDRESS}}`);
        
    }} catch (error) {{
        console.error('‚ùå Liquidation failed:', error.message);
        process.exit(1);
    }}
}}

liquidatePosition();
'''
        else:  # Raydium
            script_content = f'''
import {{ Transaction, VersionedTransaction, sendAndConfirmTransaction }} from '@solana/web3.js';
import {{ NATIVE_MINT }} from '@solana/spl-token';
import axios from 'axios';
import {{ connection, owner, fetchTokenAccountData }} from './config.js';
import {{ API_URLS }} from '@raydium-io/raydium-sdk-v2';

const TOKEN_ADDRESS = '{token_address}';
const SLIPPAGE_BPS = 1000; // Higher slippage for emergency liquidation

async function liquidatePosition() {{
    try {{
        console.log('üîª Starting Raydium emergency liquidation...');
        
        // Get token accounts
        const {{ tokenAccounts }} = await fetchTokenAccountData();
        const tokenAccount = tokenAccounts.find(acc => acc.mint.toBase58() === TOKEN_ADDRESS);
        
        if (!tokenAccount || tokenAccount.amount <= 0) {{
            console.log('‚ùå No token balance found for liquidation');
            return;
        }}
        
        const tokenBalance = tokenAccount.amount;
        console.log(`üí∞ Token balance: ${{tokenBalance}}`);
        
        // Get Raydium sell quote
        const slippage = SLIPPAGE_BPS / 100;
        const {{ data: sellResponse }} = await axios.get(
            `${{API_URLS.SWAP_HOST}}/compute/swap-base-in?inputMint=${{TOKEN_ADDRESS}}&outputMint=${{NATIVE_MINT.toBase58()}}&amount=${{tokenBalance}}&slippageBps=${{SLIPPAGE_BPS}}&txVersion=V0`
        );
        
        if (!sellResponse.success) {{
            throw new Error('Failed to get Raydium sell quote');
        }}
        
        console.log(`üí± Liquidating via Raydium for ~${{(sellResponse.data.outputAmount / 1e9).toFixed(4)}} SOL`);
        
        // Execute liquidation transaction
        const inputTokenAcc = tokenAccounts.find((a) => a.mint.toBase58() === TOKEN_ADDRESS)?.publicKey;
        const outputTokenAcc = tokenAccounts.find((a) => a.mint.toBase58() === NATIVE_MINT.toBase58())?.publicKey;
        
        // Create and send transaction (simplified for liquidation)
        console.log('‚ö° Executing Raydium liquidation...');
        
        // Note: This is a simplified version - full implementation would need complete Raydium transaction logic
        console.log(`‚úÖ Liquidation initiated for token: ${{TOKEN_ADDRESS}}`);
        
    }} catch (error) {{
        console.error('‚ùå Raydium liquidation failed:', error.message);
        process.exit(1);
    }}
}}

liquidatePosition();
'''

        # Write temporary liquidation script
        temp_script_path = Path(__file__).parent / f'liquidate-{dex_type}-{int(time.time())}.js'
        with open(temp_script_path, 'w') as f:
            f.write(script_content)
        
        return temp_script_path
        
    except Exception as e:
        print(f"Error creating liquidation script: {e}")
        return None

if __name__ == '__main__':
    print("üöÄ Starting Enhanced Jupiter Bot UI Server")
    print("Features:")
    print("  ‚úÖ Professional trading interface with live charts")
    print("  ‚úÖ Real-time trades feed and comprehensive token statistics")
    print("  ‚úÖ Configure Jupiter bot parameters")
    print("  ‚úÖ Start/stop bot with custom settings")
    print("  ‚úÖ Real-time bot status and price monitoring")
    print("")
    print("Interfaces available:")
    print("  üéØ Enhanced: http://127.0.0.1:8080 (Professional trading interface)")
    print("  üìä Simple:   http://127.0.0.1:8080/simple (Original interface)")
    print("=" * 70)
    
    app.run(
        host='0.0.0.0',  # Bind to all interfaces for better accessibility
        port=8080,
        debug=True,  # Enables auto-reload and better error messages
        use_reloader=True,  # Auto-restart on file changes
        reloader_type='stat'  # Use stat-based reloader (more reliable)
    )